{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Controlled text generation refers to generating text while exerting specific control over certain aspects of the generated output. For example, you might want to control the tone (e.g., formal or informal), style (e.g., academic or conversational), or length of the text. This kind of generation is useful in scenarios like content writing, social media post generation, and creative writing, where a particular style or tone is important.\n",
        "\n",
        "In this project, I'll implement controlled text generation using GPT-2, where we will control the tone of the generated text by conditioning it with a tone-specific input."
      ],
      "metadata": {
        "id": "gV5ghnc0lvxE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JBSuCE8LhpsJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Loading the pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"  # GPT-2 model (can be replaced with a larger model like gpt2-medium)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814,
          "referenced_widgets": [
            "5bfed9ecb1b144c1b1a18adc61da1935",
            "6fad8cc3f9574ac79f613a2d0b51a85b",
            "21d520237f214a2d9b6aefd8045c0e54",
            "7e3644b69e394a13abbefb7150f6bd1c",
            "152305debc134bab9dc970effe9fc38e",
            "d64a70cd13c74ddea46a0f466ad7f594",
            "257bd7896c04499b84839f1d3fab76d7",
            "50ce4f7843bd486da24fccd36eb89a48",
            "ac1e290ec7e74889b1f1493a8bb1b1cc",
            "92a7c1b3a588417a9c0b8e2d5b483427",
            "18325b419e484efcbd65d4791127abf9",
            "476db3cc8c5f4b5f8584319af0c00fec",
            "a559a1c4c2d140a79c7ddd5c1c270208",
            "b19c6a0713b44c1bb8c1b53fe7d338d4",
            "07be5148dbd24a0695b9e28ad60ea1bb",
            "f75ec50986234845bf30aec9209807ec",
            "6609b7e8eb2c4b558455156532007198",
            "83bcce7e6dea42c4a6087e388eab5ccf",
            "bc62434e93c34326a58307e17f7c994c",
            "399308a7ad9041fb82586b04c0507771",
            "da7c5da9205a465395fbfeb4a3eed823",
            "2ca98b69b0e44b3a9a094edc5ab88f15",
            "52a7022651d047d0bd66650b5d3a6a71",
            "ef7a20517a7d4303a71950853f1f90b6",
            "6d3b9e9665494d70a357114f56975be2",
            "bab8a5b8763546109e08716afe362d38",
            "b41ecda440a3472895460b57a0902f0e",
            "419e52d2beab470bbe1788307151ff1b",
            "758ab73c5b934af2be3cd7278205d187",
            "c9a8bb3a907049cdabc41b3928cd0c0a",
            "4542aa5d9a8e417e98145e2648b171b1",
            "dd2f5db463f54890a03864a17161bfe9",
            "d89c2aa1e2244ca186e3eca3a76fcc88",
            "1d44755745dd409ca3570cf658a4a8a5",
            "3f1361fe61f9428aabbbc8b3ccf78346",
            "62fe3a55140c4edeae3ef096340824d1",
            "6081cde3d3e6484787460a3fdb7b0c18",
            "3fd65f3dd14d4677a8641adb8e508d22",
            "8e62960f55b741c591093b35498472a4",
            "f3f4c788d56e40a2a7b515d52fc45fc4",
            "39ac191bd1424d0aa4a8ef4f08438e47",
            "01262b8f1e1441438ab5b80bf0c19b9d",
            "69644ca4aae145d88d266b37146b3c42",
            "4c541171b16c4373a91ac4d8ef02421a",
            "fb0d6dff99da48d19f319e35d1591173",
            "7a37f3bd0894470e8c35773dbf18efb1",
            "9fe2efc47e1f4120adee1d2a7b6ea4e5",
            "3d067c84111944f7aadc39270d5f0d9e",
            "65e2b003cc8c4d3ca9f7c944600a24aa",
            "5a2efe2e97054914af57f58c68bab9e3",
            "d7f6a422cd9d444a9d65d6c6d5e6ff03",
            "b6135c5afa6d4e2dbb7321b1be35d5f5",
            "499626fe6415412ea0e28d611c780f03",
            "549dc3db13a3420fbdc8358b7eeac0b4",
            "88ab694f70f14c3b9f380deff41a2998",
            "1295439784a849c299a06355d7110ce5",
            "1e4cf98e8cb140daa76d38107b3ce126",
            "fd692c74c01d4943b744f345e3a4161e",
            "03ca5c6cc4d94ccd85c93515739ad11a",
            "a6c61feab7044947abcb1b27de1e4a5e",
            "2315a2f34ba74bdfbaf8063ea2b4f2be",
            "53a6783f81c94f1bb7eda8e416cdf581",
            "ffefd54a952c49be835a06843b40ec01",
            "e84e9b1fb3ed4e6cbb7a57727ea404a1",
            "540ef6b0375d4a40a0a1ee14e3bca185",
            "8f28fbd687434723811882d5cdc5aad9",
            "24d2e2d0ba59448b9f70a8bdd9c7e894",
            "9d690d6e642f4592a4755ba682de04e2",
            "905e845dc5dd4a298d023f048506a6a0",
            "b34d5d713a03464cb0520fc296a3bfdb",
            "c59a55b2bcb64251b1c8cd6949392d65",
            "77f63543a8114cbe9425663d3b91a3ad",
            "6fe949cd3953400db8b130406583c003",
            "c7e8b7b71f904df999fb3635d39a3f1d",
            "eae08d805a0d41cca2ccd3f8ca7757b9",
            "6795fc40660d4677b0514d6af83ae9bf",
            "de960555da0449eb8321525ee73e305c"
          ]
        },
        "id": "roBlRa2-k6Y0",
        "outputId": "efb57ef4-c4d7-4e57-9187-8dc8c8927549"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bfed9ecb1b144c1b1a18adc61da1935"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "476db3cc8c5f4b5f8584319af0c00fec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52a7022651d047d0bd66650b5d3a6a71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d44755745dd409ca3570cf658a4a8a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb0d6dff99da48d19f319e35d1591173"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1295439784a849c299a06355d7110ce5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24d2e2d0ba59448b9f70a8bdd9c7e894"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generating controlled text based on a given tone or style\n",
        "def generate_controlled_text(prompt, tone=\"formal\", max_length=150, temperature=0.7, top_p=0.9):\n",
        "    # Condition the input based on tone (e.g., formal or informal)\n",
        "    conditioned_prompt = f\"Write a {tone} paragraph: {prompt}\"\n",
        "    inputs = tokenizer.encode(conditioned_prompt, return_tensors='pt')\n",
        "\n",
        "    # Generating text with the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(inputs, max_length=max_length, num_return_sequences=1,\n",
        "                                 temperature=temperature, top_p=top_p, no_repeat_ngram_size=2)\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        ""
      ],
      "metadata": {
        "id": "9VSgKpfKk-9m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Examples of controlled text generation\n",
        "prompt = \"The company's recent product launch\"\n",
        "generated_text_formal = generate_controlled_text(prompt, tone=\"formal\")\n",
        "generated_text_informal = generate_controlled_text(prompt, tone=\"informal\")\n",
        "\n",
        "print(\"Generated Formal Text:\")\n",
        "print(generated_text_formal)\n",
        "\n",
        "print(\"\\nGenerated Informal Text:\")\n",
        "print(generated_text_informal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owDZqkIUldUZ",
        "outputId": "deb1b403-abe2-40ce-afd2-2cb311fc3de5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Formal Text:\n",
            "Write a formal paragraph: The company's recent product launch is a good example of how the company is trying to make its products more accessible to the general public.\n",
            "\n",
            "The company has also been working on a new product that will allow users to use the app to access the web. The new feature will be available in the App Store on July 1.\n",
            "\n",
            "Generated Informal Text:\n",
            "Write a informal paragraph: The company's recent product launch was a success.\n",
            "\n",
            "The company has been in the news recently for its use of a \"smart\" phone, which is a device that can be used to track your location. The device is called a GPS device, and it's designed to be able to detect your movements and track you. It's also designed for use in a variety of other applications, including medical devices, medical imaging, etc. But the company is not the only company to use the device. In fact, the U.S. government has recently banned the use and use by some companies of GPS devices. And the government is also considering a ban on the sale of the devices to anyone under the age of 18\n"
          ]
        }
      ]
    }
  ]
}